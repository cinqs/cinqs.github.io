---
layout: post
title: 模型训练过程中数据的拆分使用
tags: [blog, ml]
---

> 这是一篇澄清式的文章，对入门数据挖掘或者是机器学习领域的同学有一些帮助。
> 可参阅 周志华 [《机器学习》](https://pan.baidu.com/s/1WH2omt6yGlOUXk9lQmTOUw) 一书的 2.3 章节

最近在和一些做机器学习 / 预测性分析的朋友聊天的时候，总是会对一些模型评估方面的名词，以及他们所代表的对象产生分歧。
原因大概就是来源于大家各自学习的渠道的不同造成的。于是最近找了一些资料，教科书阅读。总结了一下写在下面。

## k-fold cross-validation

> 其实对于这个也是有很多不同的理解的，我参阅的Stanford的一个教授的讲义 http://statweb.stanford.edu/~tibs/sta306bfiles/cvwrong.pdf

k-folder CV主要常见于 模型的算法选取，或者是见于算法的超参数选取的过程中。

- 将数据等分为5或者10份（shuffle firstly），可以选择其中的1份为验证集，选取另外的k-1份为训练集
- 计算在同一个模型 / 超参数组 下，k-1份训练集的综合残差，可以使用
 $$CV(\lambda) = \frac{1}{K}\sum_{k=1}^K{E_k(\lmabda)}$$
